{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python script reads file attachments from emails, converts into JSON after removing unwanted fields and required formatting, and then stores the JSON in Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import email\n",
    "import getpass\n",
    "import imaplib\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pandas.io.gbq as gbq\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readEmailAttachment(from_user):\n",
    "    #IMAP Email User/Password\n",
    "    userName = 'codebalanceit@gmail.com'\n",
    "    password = 'Hari@coding'\n",
    "    \n",
    "    imapSession = imaplib.IMAP4_SSL('imap.google.com')\n",
    "    typ, accountDetails = imapSession.login(user, pwd)\n",
    "    \n",
    "    imapSession.select()\n",
    "    typ, data = imapSession.search(None, '(FROM \"'+from_user+'\") UNSEEN')\n",
    "    \n",
    "    #iterate through all emails\n",
    "    fileNames=[]\n",
    "    for msgId in data[0].split():\n",
    "        typ, messageParts = imapSession.fetch(mgsId, '(RFC822)')\n",
    "        #get email body\n",
    "        emailBody = messageParts[0][1]\n",
    "        mail = email.message_from_bytes(emailBody)\n",
    "        for part in mail.walk():\n",
    "            fileName.append(part.get_filename())\n",
    "            \n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    # upload a file to bucket\n",
    "    # Initiate a client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "    print('File {} uploaded to {}.'.format(source_file_name,\n",
    "        destination_blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLoadTracking():\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"\n",
    "        select * from sarasmaster-201918:kopari.load_tracking\n",
    "        WHERE data_source = @source\n",
    "        AND date_from = @date_from\n",
    "        AND date_to = @date_to;\n",
    "        \"\"\"\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter('source', 'STRING', source)\n",
    "        bigquery.ScalarQueryParameter('date_from', 'STRING', date_from)\n",
    "        bigquery.ScalarQueryParameter('date_to', 'STRING', date_to)\n",
    "    ]\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.query_parameters = query_params\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        if row:\n",
    "            return('Record exists')\n",
    "        else:\n",
    "            return True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateLoadTracking(table, rows):\n",
    "    errors = client.insert_rows(table, rows)  # API request\n",
    "    assert errors == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all file attachments\n",
    "fileNames = readEmailAttachment(\"Sreehari Nambiar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fileNames:\n",
    "    for fileName in fileNames:\n",
    "        if 'Ulta' in fileName:\n",
    "            upload_blob('sarasmaster', fileName, 'kopari/retail/ulta/ulta_sales.xls')\n",
    "        elif 'Nordstorm' in fileName:\n",
    "            upload_blob('sarasmaster', fileName, 'kopari/retail/ulta/nordstrom_sales.xls')\n",
    "        elif 'Sephora' in fileName:\n",
    "            upload_blob('sarasmaster', fileName, 'kopari/retail/ulta/sephora_sales.xls')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
